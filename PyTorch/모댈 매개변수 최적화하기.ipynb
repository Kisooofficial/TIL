{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNeyyLJGJ3SqrRgge0hG5/U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"1KZb_InHuwHF","executionInfo":{"status":"ok","timestamp":1695115262825,"user_tz":-540,"elapsed":532,"user":{"displayName":"김기수","userId":"05232178571319528981"}}},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","\n","training_data = datasets.FashionMNIST(\n","    root = 'data',\n","    train = True,\n","    download = True,\n","    transform = ToTensor()\n",")\n","\n","test_data = datasets.FashionMNIST(\n","    root = 'data',\n","    train = False,\n","    download = True,\n","    transform = ToTensor()\n",")\n","\n","train_dataloader = DataLoader(training_data, batch_size = 64)\n","test_dataloader = DataLoader(test_data, batch_size = 64)\n","\n","class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super(NeuralNetwork, self).__init__()\n","        self.flatten = nn.Flatten() ## default dimension is 1\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28 * 28, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10)\n","        )\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits\n","\n","model = NeuralNetwork()"]},{"cell_type":"code","source":["learning_rate = 1e-3\n","batch_size = 64\n","epochs = 5"],"metadata":{"id":"g5CaUbpjvjTV","executionInfo":{"status":"ok","timestamp":1695115455708,"user_tz":-540,"elapsed":3,"user":{"displayName":"김기수","userId":"05232178571319528981"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def train_loop(dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset)\n","    for batch, (X, y) in enumerate(dataloader):\n","        ## 예측과 손실 계산\n","        preds = model(X)\n","        loss = loss_fn(preds, y)\n","\n","        ## 역전파 진행\n","        optimizer.zero_grad() ## 모든 매개변수들의 변화도를 0으로 저장하고 시작\n","        loss.backward() ## 예측 손실에 대한 역전파 진행. PyTorch는 각 매개변수에 대한 손실의 변화도를 저장\n","        optimizer.step() # 역전파 단계에서 수집된 변화도로 매개변수를 조정함\n","\n","        if batch % 100 == 0:\n","            loss, current = loss.item(), (batch + 1) * len(X)\n","            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n","\n","def test_loop(dataloader, model, loss_fn):\n","    model.eval()\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    test_loss, correct = 0, 0\n","\n","    with torch.no_grad():\n","        for X, y in dataloader:\n","            pred = model(X)\n","            test_loss += loss_fn(pred, y).item()\n","            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","\n","    test_loss /= num_batches\n","    correct /= size\n","    print(f'Test Error: \\n Accuracy: {(100*correct) : >0.1f}%, Avg loss : {test_loss:>8f} \\n')"],"metadata":{"id":"u36HSJ62wSer","executionInfo":{"status":"ok","timestamp":1695116214732,"user_tz":-540,"elapsed":7,"user":{"displayName":"김기수","userId":"05232178571319528981"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["model = NeuralNetwork()\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n","\n","epochs = 10\n","for t in range(epochs):\n","    print(f'Epoch {t+1}\\n--------------------------')\n","    train_loop(train_dataloader, model, loss_fn, optimizer)\n","    test_loop(test_dataloader, model, loss_fn)\n","\n","print('Done!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"haoRpMP4x8Yt","executionInfo":{"status":"ok","timestamp":1695116469997,"user_tz":-540,"elapsed":139992,"user":{"displayName":"김기수","userId":"05232178571319528981"}},"outputId":"462cdd8b-d0bf-4895-cd8d-2676a9841f94"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","--------------------------\n","loss: 2.299848  [   64/60000]\n","loss: 2.289236  [ 6464/60000]\n","loss: 2.278111  [12864/60000]\n","loss: 2.272282  [19264/60000]\n","loss: 2.254996  [25664/60000]\n","loss: 2.224662  [32064/60000]\n","loss: 2.225282  [38464/60000]\n","loss: 2.190736  [44864/60000]\n","loss: 2.183239  [51264/60000]\n","loss: 2.158673  [57664/60000]\n","Test Error: \n"," Accuracy: 53.0%, Avg loss : 2.154599 \n","\n","Epoch 2\n","--------------------------\n","loss: 2.157562  [   64/60000]\n","loss: 2.147158  [ 6464/60000]\n","loss: 2.095896  [12864/60000]\n","loss: 2.113971  [19264/60000]\n","loss: 2.064977  [25664/60000]\n","loss: 1.999688  [32064/60000]\n","loss: 2.018820  [38464/60000]\n","loss: 1.940015  [44864/60000]\n","loss: 1.944428  [51264/60000]\n","loss: 1.866601  [57664/60000]\n","Test Error: \n"," Accuracy: 62.1%, Avg loss : 1.878058 \n","\n","Epoch 3\n","--------------------------\n","loss: 1.907127  [   64/60000]\n","loss: 1.876403  [ 6464/60000]\n","loss: 1.768973  [12864/60000]\n","loss: 1.805123  [19264/60000]\n","loss: 1.701433  [25664/60000]\n","loss: 1.646374  [32064/60000]\n","loss: 1.657382  [38464/60000]\n","loss: 1.562518  [44864/60000]\n","loss: 1.596390  [51264/60000]\n","loss: 1.469989  [57664/60000]\n","Test Error: \n"," Accuracy: 62.3%, Avg loss : 1.509049 \n","\n","Epoch 4\n","--------------------------\n","loss: 1.580499  [   64/60000]\n","loss: 1.542134  [ 6464/60000]\n","loss: 1.401897  [12864/60000]\n","loss: 1.463597  [19264/60000]\n","loss: 1.344513  [25664/60000]\n","loss: 1.341305  [32064/60000]\n","loss: 1.346752  [38464/60000]\n","loss: 1.273146  [44864/60000]\n","loss: 1.317932  [51264/60000]\n","loss: 1.200565  [57664/60000]\n","Test Error: \n"," Accuracy: 63.4%, Avg loss : 1.241887 \n","\n","Epoch 5\n","--------------------------\n","loss: 1.325656  [   64/60000]\n","loss: 1.303546  [ 6464/60000]\n","loss: 1.142836  [12864/60000]\n","loss: 1.240912  [19264/60000]\n","loss: 1.110234  [25664/60000]\n","loss: 1.141894  [32064/60000]\n","loss: 1.157931  [38464/60000]\n","loss: 1.093281  [44864/60000]\n","loss: 1.141978  [51264/60000]\n","loss: 1.045215  [57664/60000]\n","Test Error: \n"," Accuracy: 64.8%, Avg loss : 1.077922 \n","\n","Epoch 6\n","--------------------------\n","loss: 1.155283  [   64/60000]\n","loss: 1.154358  [ 6464/60000]\n","loss: 0.974570  [12864/60000]\n","loss: 1.103745  [19264/60000]\n","loss: 0.973160  [25664/60000]\n","loss: 1.010745  [32064/60000]\n","loss: 1.044312  [38464/60000]\n","loss: 0.980801  [44864/60000]\n","loss: 1.029632  [51264/60000]\n","loss: 0.950076  [57664/60000]\n","Test Error: \n"," Accuracy: 65.9%, Avg loss : 0.974223 \n","\n","Epoch 7\n","--------------------------\n","loss: 1.038188  [   64/60000]\n","loss: 1.059238  [ 6464/60000]\n","loss: 0.861802  [12864/60000]\n","loss: 1.013205  [19264/60000]\n","loss: 0.890279  [25664/60000]\n","loss: 0.919454  [32064/60000]\n","loss: 0.971017  [38464/60000]\n","loss: 0.908024  [44864/60000]\n","loss: 0.952902  [51264/60000]\n","loss: 0.886853  [57664/60000]\n","Test Error: \n"," Accuracy: 67.1%, Avg loss : 0.904040 \n","\n","Epoch 8\n","--------------------------\n","loss: 0.952584  [   64/60000]\n","loss: 0.993417  [ 6464/60000]\n","loss: 0.781945  [12864/60000]\n","loss: 0.949010  [19264/60000]\n","loss: 0.836482  [25664/60000]\n","loss: 0.853445  [32064/60000]\n","loss: 0.919751  [38464/60000]\n","loss: 0.859144  [44864/60000]\n","loss: 0.897651  [51264/60000]\n","loss: 0.841175  [57664/60000]\n","Test Error: \n"," Accuracy: 68.4%, Avg loss : 0.853532 \n","\n","Epoch 9\n","--------------------------\n","loss: 0.887249  [   64/60000]\n","loss: 0.944182  [ 6464/60000]\n","loss: 0.722581  [12864/60000]\n","loss: 0.901254  [19264/60000]\n","loss: 0.798219  [25664/60000]\n","loss: 0.804400  [32064/60000]\n","loss: 0.880964  [38464/60000]\n","loss: 0.825196  [44864/60000]\n","loss: 0.856315  [51264/60000]\n","loss: 0.806233  [57664/60000]\n","Test Error: \n"," Accuracy: 69.6%, Avg loss : 0.815209 \n","\n","Epoch 10\n","--------------------------\n","loss: 0.835164  [   64/60000]\n","loss: 0.904556  [ 6464/60000]\n","loss: 0.676389  [12864/60000]\n","loss: 0.864064  [19264/60000]\n","loss: 0.768964  [25664/60000]\n","loss: 0.767102  [32064/60000]\n","loss: 0.849515  [38464/60000]\n","loss: 0.800386  [44864/60000]\n","loss: 0.824316  [51264/60000]\n","loss: 0.778237  [57664/60000]\n","Test Error: \n"," Accuracy: 70.6%, Avg loss : 0.784693 \n","\n","Done!\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"NwED8XL8yR1p"},"execution_count":null,"outputs":[]}]}